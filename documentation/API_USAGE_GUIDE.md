<!-- documentation/API_USAGE_GUIDE.md -->
# Uformer FastAPI Hub: API Usage Guide

**Document Version:** 1.0  
**Date:** 2025-06-23<br>

Welcome to the Uformer FastAPI Hub API. This guide provides instructions for third-party developers on how to integrate our powerful image and video enhancement services into their own applications.

---

## 1. Core Concepts & Interactive Docs

The API provides endpoints for real-time and file-based enhancement of images and videos using state-of-the-art Uformer models.

### 1.1. Interactive API Documentation (The Source of Truth)

A complete, interactive specification of every available REST endpoint, including all required parameters, request bodies, and response models, is automatically generated by the server. **This is the definitive reference for all technical details.**

*   **Swagger UI (Recommended):** [http://localhost:8000/docs](http://localhost:8000/docs)
*   **ReDoc:** [http://localhost:8000/redoc](http://localhost:8000/redoc)

This guide focuses on the high-level workflow and how to use the different features together.

### 1.2. Asynchronous by Design

All file processing operations (for images and videos) are **asynchronous**. You will not receive the processed file in the same request you use to upload it. Instead, you will receive a `task_id` and must poll a status endpoint to get the result. This non-blocking pattern is designed for handling long-running tasks without tying up connections.

---

## 2. Workflow: Asynchronous File Processing

This "Start-and-Poll" workflow applies to both the **Image Processor** and **Video Processor**.

### Step 1: Start the Processing Task

To begin, send a `POST` request with `multipart/form-data` to the appropriate endpoint:
*   **Image Processing:** `/api/process_image`
*   **Video Processing:** `/api/process_video`

**Request Body:**

| Parameter              | Type       | Description                                                                 |
| ---------------------- | ---------- | --------------------------------------------------------------------------- |
| `image_file` or `video_file` | `File`     | The image or video file to be processed.                                    |
| `task_type`            | `str`      | The task to perform. E.g., `'denoise'` or `'deblur'`.                 |
| `model_name`           | `str`      | The specific model to use. E.g., `'denoise_16'`, `'deblur_b'`.           |
| `use_patch_processing` | `bool`     | (Image Only) `true` for high-quality patch-based processing (recommended). |

**Successful Response (`202 Accepted`):**
If the request is valid, the server accepts the task and immediately responds with a JSON object containing the `task_id`.

```json
{
  "task_id": "a1b2c3d4-e5f6-7890-a1b2-c3d4e5f67890",
  "message": "Image processing task started."
}
```
Store this `task_id`. You will need it for the next step.

### Step 2: Poll for Task Status

Once you have a `task_id`, begin polling the relevant status endpoint with a `GET` request every 2-5 seconds.

*   **Image Status:** `/api/image_status/{task_id}`
*   **Video Status:** `/api/video_status/{task_id}`

The response will be a JSON object detailing the task's current state.

**Example Response (while processing):**
```json
{
  "status": "processing",
  "progress": 42,
  "message": "Processing..."
}
```

Continue polling as long as the `status` is `'pending'` or `'processing'`.

### Step 3: Retrieve the Result

When the status poll returns a `completed` status, stop polling. The response object will now contain a `result_path`.

**Example Response (on completion):**
```json
{
  "status": "completed",
  "result_path": "/static_results/images/denoise/processed/1678886400_a1b2c3d4_processed_image.jpg"
}
```
To create the full, downloadable URL, prepend the API's base address:
`http://localhost:8000` + `[result_path]`

---

## 3. Workflow: Real-Time Live Stream Processing

The live stream processor uses a WebSocket connection for low-latency, frame-by-frame enhancement.

**Endpoint:** `ws://localhost:8000/ws/process_video`

### Step 1: Establish Connection

Connect to the WebSocket endpoint from your client application.

### Step 2: Send Frames

For each frame you want to process, send a JSON object with the following structure:

**Request Payload (JSON):**
```json
{
  "image_b64": "data:image/jpeg;base64,...",
  "task_type": "denoise",
  "model_name": "denoise_16",
  "use_patch_processing": false,
  "show_fps": true
}
```
*   `image_b64`: A Base64-encoded data URL of the video frame.
*   `use_patch_processing`: `false` is strongly recommended for real-time performance.

### Step 3: Receive Enhanced Frames

The server will respond to each message with the enhanced frame as a Base64-encoded data URL, which can be directly used as the `src` for an `<img>` tag.

**Example Response (Text):**
`data:image/jpeg;base64,...`

---

## 4. Resource & UI Management

These endpoints allow for building a sophisticated UI that can manage server resources dynamically.

### 4.1. Dynamic UI Configuration

This is the most important endpoint for building a client application. It provides all the necessary information to dynamically generate UI controls, such as task and model dropdowns.

**Endpoint:** `GET /api/available_controls`

**Example Response (`200 OK`):**
```json
{
  "tasks": {
    "denoise": {
      "display_name": "Denoise",
      "models": [
        { "value": "denoise_16", "text": "Uformer-16 (Fast)" },
        { "value": "denoise_b", "text": "Uformer-B (High Quality)" }
      ]
    },
    "deblur": {
      "display_name": "Deblur",
      "models": [
        { "value": "deblur_b", "text": "Uformer-B (Deblur)" }
      ]
    }
  },
  "page_controls": {
    "live": { "patch_processing": { "available": true, "default_checked": false, ... }},
    "image": { "patch_processing": { "available": true, "default_checked": true, ... }},
    "video": { "patch_processing": { "available": false, ... }}
  }
}
```

### 4.2. VRAM Management (On-Demand Loading)

These endpoints are used to manage models in GPU VRAM, primarily when the server is running in on-demand loading mode (`LOAD_ALL_MODELS_ON_STARTUP=False`).

*   `GET /api/model_loading_strategy`: Returns `{"load_all_on_startup": false}`. Use this to determine if VRAM controls should be visible in the UI.
*   `GET /api/loaded_models_status`: Returns a list of all models and their current `loaded` status (boolean).
*   `POST /api/unload_models`: Unloads models from VRAM. Send a JSON body `{"model_names": ["denoise_b"]}` to unload specific models, or an empty list `[]` to attempt to unload all. The server will not unload models currently in use.

### 4.3. Cache Management

These endpoints manage the temporary files stored on the server's disk.

*   `GET /api/cache_status`: Returns the current size (in MB) of the image and video caches.
*   `POST /api/clear_cache`: A powerful endpoint to clear unprotected files. It takes boolean query parameters `?clear_images=true&clear_videos=true`. It will not delete files that are actively being processed or are awaiting user download.
*   `POST /api/confirm_download`: **Crucial for cache cleanup.** After a user starts a download, call this endpoint with the file's `result_path` in the JSON body. This marks the file as "downloaded" and allows the server's automated cleanup task to eventually remove it after a grace period.
*   `POST /api/task_heartbeat`: If a result is being displayed for a long time without being downloaded, call this endpoint periodically (e.g., every 5 minutes) with the `task_id`. This keeps the file "alive" and prevents it from being deleted.
